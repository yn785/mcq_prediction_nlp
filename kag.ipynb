{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>What is the relation between the three moment ...</td>\n",
       "      <td>The three moment theorem expresses the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem describes the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem is used to derive the...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>What is the throttling process, and why is it ...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>What happens to excess base metal as a solutio...</td>\n",
       "      <td>The excess base metal will often solidify, bec...</td>\n",
       "      <td>The excess base metal will often crystallize-o...</td>\n",
       "      <td>The excess base metal will often dissolve, bec...</td>\n",
       "      <td>The excess base metal will often liquefy, beco...</td>\n",
       "      <td>The excess base metal will often evaporate, be...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>What is the relationship between mass, force, ...</td>\n",
       "      <td>Mass is a property that determines the weight ...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is a property that determines the size of...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>What did Arthur Eddington discover about two o...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "id                                                       \n",
       "0    Which of the following statements accurately d...   \n",
       "1    Which of the following is an accurate definiti...   \n",
       "2    Which of the following statements accurately d...   \n",
       "3    What is the significance of regularization in ...   \n",
       "4    Which of the following statements accurately d...   \n",
       "..                                                 ...   \n",
       "195  What is the relation between the three moment ...   \n",
       "196  What is the throttling process, and why is it ...   \n",
       "197  What happens to excess base metal as a solutio...   \n",
       "198  What is the relationship between mass, force, ...   \n",
       "199  What did Arthur Eddington discover about two o...   \n",
       "\n",
       "                                                     A  \\\n",
       "id                                                       \n",
       "0    MOND is a theory that reduces the observed mis...   \n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol was reconstructed as a fe...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem expresses the relatio...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often solidify, bec...   \n",
       "198  Mass is a property that determines the weight ...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     B  \\\n",
       "id                                                       \n",
       "0    MOND is a theory that increases the discrepanc...   \n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol is a representation of th...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often crystallize-o...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     C  \\\n",
       "id                                                       \n",
       "0    MOND is a theory that explains the missing bar...   \n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol is a representation of a ...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem describes the relatio...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often dissolve, bec...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     D  \\\n",
       "id                                                       \n",
       "0    MOND is a theory that reduces the discrepancy ...   \n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol represents three interloc...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often liquefy, beco...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     E answer  \n",
       "id                                                             \n",
       "0    MOND is a theory that eliminates the observed ...      D  \n",
       "1    Dynamic scaling refers to the evolution of sel...      A  \n",
       "2    The triskeles symbol is a representation of th...      A  \n",
       "3    Regularizing the mass-energy of an electron wi...      C  \n",
       "4    The angular spacing of features in the diffrac...      D  \n",
       "..                                                 ...    ...  \n",
       "195  The three moment theorem is used to derive the...      C  \n",
       "196  The throttling process is a steady adiabatic f...      B  \n",
       "197  The excess base metal will often evaporate, be...      B  \n",
       "198  Mass is a property that determines the size of...      D  \n",
       "199  Arthur Eddington showed that two of Einstein's...      C  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('train.csv')\n",
    "df.set_index('id',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "def preprocesstext(text,stopwords,lemmatizer):\n",
    "    text=text.lower()\n",
    "    text= re.sub(r'[!(),?\\'`]','',text)\n",
    "    token= word_tokenize(text)\n",
    "    tokens= [tokens for tokens in token if tokens not in stopwords]\n",
    "    tokens= [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "\n",
    "    return ' '.join(tokens)\n",
    "stopwords=set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "prompts=[]\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "E=[]\n",
    "for i in df['prompt']:\n",
    "    prompts.append(preprocesstext(i,stopwords,lemmatizer))\n",
    "for i in df['A']:\n",
    "    A.append(preprocesstext(i,stopwords,lemmatizer))\n",
    "for i in df['B']:\n",
    "    B.append(preprocesstext(i,stopwords,lemmatizer))\n",
    "for i in df['C']:\n",
    "    C.append(preprocesstext(i,stopwords,lemmatizer))\n",
    "for i in df['D']:\n",
    "    D.append(preprocesstext(i,stopwords,lemmatizer))\n",
    "for i in df['E']:\n",
    "    E.append(preprocesstext(i,stopwords,lemmatizer))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW AND IF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt\n",
    "\n",
    "vec= CountVectorizer()\n",
    "bow=vec.fit_transform(prompts)\n",
    "column=vec.get_feature_names_out()\n",
    "ins=TfidfTransformer()\n",
    "ifidf=ins.fit_transform(bow)\n",
    "new=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "#A\n",
    "vec= CountVectorizer()\n",
    "bow=vec.fit_transform(A)\n",
    "column=vec.get_feature_names_out()\n",
    "ins=TfidfTransformer()\n",
    "ifidf=ins.fit_transform(bow)\n",
    "new1=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "#B\n",
    "vec= CountVectorizer()\n",
    "bow=vec.fit_transform(B)\n",
    "column=vec.get_feature_names_out()\n",
    "ins=TfidfTransformer()\n",
    "ifidf=ins.fit_transform(bow)\n",
    "new2=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "#C\n",
    "vec= CountVectorizer()\n",
    "bow=vec.fit_transform(C)\n",
    "column=vec.get_feature_names_out()\n",
    "ins=TfidfTransformer()\n",
    "ifidf=ins.fit_transform(bow)\n",
    "new3=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "#D\n",
    "vec= CountVectorizer()\n",
    "bow=vec.fit_transform(D)\n",
    "column=vec.get_feature_names_out()\n",
    "ins=TfidfTransformer()\n",
    "ifidf=ins.fit_transform(bow)\n",
    "new4=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "#E\n",
    "vec= CountVectorizer()\n",
    "bow=vec.fit_transform(E)\n",
    "column=vec.get_feature_names_out()\n",
    "ins=TfidfTransformer()\n",
    "ifidf=ins.fit_transform(bow)\n",
    "new5=pd.DataFrame(ifidf.toarray(),columns=column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2588)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([new, new1, new2,new3,new4,new5], axis=1)\n",
    "merged_df = combined_df.groupby(combined_df.columns, axis=1).sum()\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 2, 3, 1, 0, 3, 2, 0, 4, 0, 2, 3, 1, 1, 4, 4, 0, 4, 3, 3,\n",
       "       2, 2, 4, 4, 0, 3, 4, 2, 1, 4, 4, 3, 2, 1, 4, 0, 4, 4, 4, 2, 1, 2,\n",
       "       0, 0, 1, 2, 3, 1, 1, 4, 2, 0, 1, 1, 2, 2, 3, 0, 1, 1, 2, 2, 0, 4,\n",
       "       2, 4, 2, 3, 2, 0, 3, 1, 3, 1, 3, 1, 2, 4, 2, 0, 1, 0, 2, 3, 3, 1,\n",
       "       4, 3, 1, 1, 1, 4, 4, 2, 2, 3, 3, 3, 3, 1, 2, 1, 2, 3, 0, 3, 0, 3,\n",
       "       2, 3, 0, 1, 3, 4, 1, 2, 3, 0, 0, 2, 1, 0, 1, 3, 1, 2, 4, 4, 0, 2,\n",
       "       4, 1, 2, 4, 4, 3, 0, 0, 2, 4, 1, 0, 2, 1, 1, 2, 1, 1, 1, 3, 0, 0,\n",
       "       1, 4, 3, 2, 0, 0, 0, 4, 1, 1, 2, 3, 1, 3, 4, 0, 1, 4, 1, 2, 1, 4,\n",
       "       3, 3, 2, 2, 1, 0, 0, 2, 0, 0, 2, 0, 3, 1, 4, 2, 1, 1, 3, 2, 1, 1,\n",
       "       3, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(df['answer'])\n",
    "\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.38      0.50      0.43        12\n",
      "           2       0.07      0.20      0.11         5\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.20        40\n",
      "   macro avg       0.12      0.24      0.16        40\n",
      "weighted avg       0.13      0.20      0.15        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "X=merged_df\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=0)\n",
    "lr=LogisticRegression(multi_class='multinomial')\n",
    "lr.fit(X_train,y_train)\n",
    "print(classification_report(y_test,lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Assuming you have trained the logistic regression model and have X_test and y_test\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = lr.predict_proba(X_test)\n",
    "\n",
    "# Convert y_test to binary indicator format\n",
    "n_classes = y_pred_prob.shape[1]\n",
    "y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "# Calculate average precision at each rank for each sample\n",
    "avg_precision_scores = []\n",
    "for i in range(n_classes):\n",
    "    avg_precision_scores.append(average_precision_score(y_test_bin[:, i], y_pred_prob[:, i]))\n",
    "\n",
    "# Calculate MAP@3\n",
    "map_3 = sum(sorted(avg_precision_scores, reverse=True)[:3]) / min(len(avg_precision_scores), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42890250859271944\n"
     ]
    }
   ],
   "source": [
    "print(map_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        12\n",
      "           1       0.38      0.25      0.30        12\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.20      0.11      0.14         9\n",
      "           4       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.15        40\n",
      "   macro avg       0.20      0.19      0.16        40\n",
      "weighted avg       0.24      0.15      0.17        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB=GradientBoostingClassifier(learning_rate=0.1)\n",
    "GB.fit(X_train,y_train)\n",
    "print(classification_report(y_test,GB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33890768738813204\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_prob = GB.predict_proba(X_test)\n",
    "\n",
    "# Convert y_test to binary indicator format\n",
    "n_classes = y_pred_prob.shape[1]\n",
    "y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "# Calculate average precision at each rank for each sample\n",
    "avg_precision_scores = []\n",
    "for i in range(n_classes):\n",
    "    avg_precision_scores.append(average_precision_score(y_test_bin[:, i], y_pred_prob[:, i]))\n",
    "\n",
    "# Calculate MAP@3\n",
    "map_3 = sum(sorted(avg_precision_scores, reverse=True)[:3]) / min(len(avg_precision_scores), 3)\n",
    "print(map_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS TREE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33        12\n",
      "           1       0.31      0.33      0.32        12\n",
      "           2       0.22      0.40      0.29         5\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.25        40\n",
      "   macro avg       0.23      0.30      0.22        40\n",
      "weighted avg       0.28      0.25      0.24        40\n",
      "\n",
      "0.29252136752136754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT=DecisionTreeClassifier()\n",
    "DT.fit(X_train,y_train)\n",
    "print(classification_report(y_test,DT.predict(X_test)))\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = DT.predict_proba(X_test)\n",
    "\n",
    "# Convert y_test to binary indicator format\n",
    "n_classes = y_pred_prob.shape[1]\n",
    "y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "# Calculate average precision at each rank for each sample\n",
    "avg_precision_scores = []\n",
    "for i in range(n_classes):\n",
    "    avg_precision_scores.append(average_precision_score(y_test_bin[:, i], y_pred_prob[:, i]))\n",
    "\n",
    "# Calculate MAP@3\n",
    "map_3 = sum(sorted(avg_precision_scores, reverse=True)[:3]) / min(len(avg_precision_scores), 3)\n",
    "print(map_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.80      0.33      0.47        12\n",
      "           2       0.16      1.00      0.28         5\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.23        40\n",
      "   macro avg       0.19      0.27      0.15        40\n",
      "weighted avg       0.26      0.23      0.18        40\n",
      "\n",
      "0.3456947375985959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yn/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yn/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yn/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "print(classification_report(y_test,rfc.predict(X_test)))\n",
    "y_pred_prob = rfc.predict_proba(X_test)\n",
    "\n",
    "# Convert y_test to binary indicator format\n",
    "n_classes = y_pred_prob.shape[1]\n",
    "y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "# Calculate average precision at each rank for each sample\n",
    "avg_precision_scores = []\n",
    "for i in range(n_classes):\n",
    "    avg_precision_scores.append(average_precision_score(y_test_bin[:, i], y_pred_prob[:, i]))\n",
    "\n",
    "# Calculate MAP@3\n",
    "map_3 = sum(sorted(avg_precision_scores, reverse=True)[:3]) / min(len(avg_precision_scores), 3)\n",
    "print(map_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 0 2 2 2 0 2 2 0 4 0 3 3 1 1 1 4 3 4 3 3 2 2 4 4 0 3 4 2 1 4 4 2 2 1 4\n",
      " 4 4 4 4 2 1 2 2 4 1 2 3 1 1 4 2 0 1 1 2 2 3 0 2 1 2 2 0 4 2 4 2 3 2 0 3 1\n",
      " 2 1 3 1 2 4 1 0 1 4 2 3 3 1 4 3 1 1 1 4 4 2 2 3 2 3 3 1 2 1 2 3 2 4 0 3 2\n",
      " 1 0 1 3 4 1 2 3 0 0 2 2 1 1 2 1 2 4 4 1 2 4 1 2 4 4 3 0 0 2 4 1 0 2 0 2 2\n",
      " 1 1 1 3 1 0 1 4 3 2 0 2 0 4 1 1 2 3 1 3 4 0 1 4 1 2 1 4 3 1 2 1 3 0 4 1 0\n",
      " 1 2 0 3 1 4 2 1 1 3 2 1 1 3 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.68      0.79        37\n",
      "           1       0.81      0.88      0.84        48\n",
      "           2       0.75      0.91      0.82        44\n",
      "           3       0.91      0.76      0.83        38\n",
      "           4       0.86      0.97      0.91        33\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.86      0.84      0.84       200\n",
      "weighted avg       0.85      0.84      0.84       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def testpreprocesstext(text,stopwords,lemmatizer):\n",
    "    text=text.lower()\n",
    "    text= re.sub(r'[!(),?\\'`]','',text)\n",
    "    token= word_tokenize(text)\n",
    "    tokens= [tokens for tokens in token if tokens not in stopwords]\n",
    "    tokens= [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "def newtest():\n",
    "    df=pd.read_csv('test.csv')\n",
    "    #stopwords=set(stopwords.words('english'))\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    prompts=[]\n",
    "    A=[]\n",
    "    B=[]\n",
    "    C=[]\n",
    "    D=[]\n",
    "    E=[]\n",
    "    for i in df['prompt']:\n",
    "        prompts.append(testpreprocesstext(i,stopwords,lemmatizer))\n",
    "    for i in df['A']:\n",
    "        A.append(testpreprocesstext(i,stopwords,lemmatizer))\n",
    "    for i in df['B']:\n",
    "        B.append(testpreprocesstext(i,stopwords,lemmatizer))\n",
    "    for i in df['C']:\n",
    "        C.append(testpreprocesstext(i,stopwords,lemmatizer))\n",
    "    for i in df['D']:\n",
    "        D.append(testpreprocesstext(i,stopwords,lemmatizer))\n",
    "    for i in df['E']:\n",
    "        E.append(testpreprocesstext(i,stopwords,lemmatizer))\n",
    "    #prompt\n",
    "    vec= CountVectorizer()\n",
    "    bow=vec.fit_transform(prompts)\n",
    "    column=vec.get_feature_names_out()\n",
    "    ins=TfidfTransformer()\n",
    "    ifidf=ins.fit_transform(bow)\n",
    "    new=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "    #A\n",
    "    vec= CountVectorizer()\n",
    "    bow=vec.fit_transform(A)\n",
    "    column=vec.get_feature_names_out()\n",
    "    ins=TfidfTransformer()\n",
    "    ifidf=ins.fit_transform(bow)\n",
    "    new1=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "    #B\n",
    "    vec= CountVectorizer()\n",
    "    bow=vec.fit_transform(B)\n",
    "    column=vec.get_feature_names_out()\n",
    "    ins=TfidfTransformer()\n",
    "    ifidf=ins.fit_transform(bow)\n",
    "    new2=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "    #C\n",
    "    vec= CountVectorizer()\n",
    "    bow=vec.fit_transform(C)\n",
    "    column=vec.get_feature_names_out()\n",
    "    ins=TfidfTransformer()\n",
    "    ifidf=ins.fit_transform(bow)\n",
    "    new3=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "    #D\n",
    "    vec= CountVectorizer()\n",
    "    bow=vec.fit_transform(D)\n",
    "    column=vec.get_feature_names_out()\n",
    "    ins=TfidfTransformer()\n",
    "    ifidf=ins.fit_transform(bow)\n",
    "    new4=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "    #E\n",
    "    vec= CountVectorizer()\n",
    "    bow=vec.fit_transform(E)\n",
    "    column=vec.get_feature_names_out()\n",
    "    ins=TfidfTransformer()\n",
    "    ifidf=ins.fit_transform(bow)\n",
    "    new5=pd.DataFrame(ifidf.toarray(),columns=column)\n",
    "    combined_df = pd.concat([new, new1, new2,new3,new4,new5], axis=1)\n",
    "    merged_df = combined_df.groupby(combined_df.columns, axis=1).sum()\n",
    "    return merged_df\n",
    "print(lr.predict(newtest()))\n",
    "print(classification_report(y,lr.predict(newtest())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prediction'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred_prob = lr.predict_proba(newtest())\n",
    "\n",
    "# Get the indices of the top 3 predictions for each sample\n",
    "top_3_indices = np.argsort(-y_pred_prob, axis=1)[:, :3]\n",
    "new_df=pd.read_csv('test.csv')\n",
    "# Create a DataFrame with the \"ID\" column\n",
    "df_predictions = pd.DataFrame({'id': new_df['id']})\n",
    "# Add the \"prediction\" column to the DataFrame, containing the top 3 predictions (alphabetical labels)\n",
    "df_predictions['prediction'] = [' '.join(label_encoder.inverse_transform(top_3_indices[i])) for i in range(len(y_pred_prob))]\n",
    "\"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions\n",
    "df_predictions.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
